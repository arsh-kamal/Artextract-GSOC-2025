{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RGA9Fick4B3a",
        "Qt4nh87Z4pQM"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arsh-kamal/Artextract-GSOC-2025/blob/main/assignment7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGA9Fick4B3a"
      },
      "source": [
        "# Initialization, utilities (no TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUIdICI1s_b"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import argparse\n",
        "import PIL\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yu9m7Fp2Igo"
      },
      "source": [
        "def to_list(img):\n",
        "    return list(map(int, img.view((28*28,)).tolist()))\n",
        "\n",
        "SCALE_OFF = 0\n",
        "SCALE_RANGE = 1\n",
        "SCALE_01 = 2\n",
        "\n",
        "\n",
        "def show_image(tens, imgname=None, scale=SCALE_01):\n",
        "    \"\"\"\n",
        "    Show an image contained in a tensor. The tensor will be reshaped properly, as long as it has the required 28*28 = 784 entries.\n",
        "\n",
        "    If imgname is provided, the image will be saved to a file, otherwise it will be stored in a temporary file and displayed on screen.\n",
        "\n",
        "    The parameter scale can be used to perform one of three scaling operations:\n",
        "        SCALE_OFF: No scaling is performed, the data is expected to use values between 0 and 255\n",
        "        SCALE_RANGE: The data will be rescaled from whichever scale it has to be between 0 and 255. This is useful for data in an unknown/arbitrary range. The lowest value present in the data will be\n",
        "        converted to 0, the highest to 255, and all intermediate values will be assigned using linear interpolation\n",
        "        SCALE_01: The data will be rescaled from a range between 0 and 1 to the range between 0 and 255. This can be useful if you normalize your data into that range.\n",
        "    \"\"\"\n",
        "    r = tens.max() - tens.min()\n",
        "    img = PIL.Image.new(\"L\", (28,28))\n",
        "    scaled = tens\n",
        "    if scale == SCALE_RANGE:\n",
        "        scaled = (tens - tens.min())*255/r\n",
        "    elif scale == SCALE_01:\n",
        "        scaled = tens*255\n",
        "    img.putdata(to_list(scaled))\n",
        "    if imgname is None:\n",
        "        img.show()\n",
        "    else:\n",
        "        img.save(imgname)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzidJ5p_3rD9"
      },
      "source": [
        "# Classification (5 TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "386jsZ5k1vX2"
      },
      "source": [
        "# Used for both tasks\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "# TODO 1: Choose a digit\n",
        "digit = 7\n",
        "\n",
        "# TODO 2: Change number of training iterations for classifier\n",
        "n0 = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkMT2Ian4Y62"
      },
      "source": [
        "# TODO 3\n",
        "# Change Network architecture of the discriminator/classifier network. It should have 784 inputs and 1 output (0 = fake, 1 = real)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na_-h3hb4gFr"
      },
      "source": [
        "# TODO 4\n",
        "# Implement training loop for the classifier:\n",
        "# for i in range(n0):\n",
        "#     zero gradients\n",
        "#     calculate predictions for given x\n",
        "#     calculate loss, comparing the predictions with the given y\n",
        "#     calculate the gradient (loss.backward())\n",
        "#     print i and the loss\n",
        "#     perform an optimizer step\n",
        "def train_classifier(opt, model, x, y):\n",
        "    model.train()\n",
        "    for i in range(n0):\n",
        "        opt.zero_grad()  # Zero gradients\n",
        "        y_pred = model(x)  # Calculate predictions\n",
        "        loss = loss_fn(y_pred, y)  # Calculate loss\n",
        "        loss.backward()  # Calculate gradients\n",
        "        print(f\"Iteration {i}, Loss: {loss.item():.4f}\")\n",
        "        opt.step()  # Perform optimizer step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFhul0ET4i9p"
      },
      "source": [
        "# TODO 5\n",
        "# Instantiate the network and the optimizer\n",
        "# call train_classifier with the training set\n",
        "# Calculate metrics on the validation set\n",
        "# Example:\n",
        "#      y_pred = net(x_validation[labels_validation == 3]) calculates all predictions for all images we know to be 3s\n",
        "#      (y_pred > 0.5) is a tensor that tells you if a given image was classified as your chosen digit (True) or not (False)\n",
        "#      You can convert this tensor to 0s and 1s by calling .float()\n",
        "#      (y_pred > 0.5).sum() will tell you how many of these predictions were true\n",
        "# You are supposed to calculate:\n",
        "#     For each digit from 0 to 9, which number percentage of images that were of that digit were predicted as your chosen digit\n",
        "#     The percentage of digits that were classified correctly (i.e. that were your digit and predicted as such, or were another digit and not predicted as your digit)\n",
        "#     This last value (accuracy) should be over 90% (preferably over 98%; precision and recall may be lower than that, 90-93% would be decent values)\n",
        "#     Precision (which percentage of images identified as your chosen digit was actually that digit: TP/(TP+FP))\n",
        "#     Recall (which percentage of your chosen digit was identified as such: TP/(TP+FN))\n",
        "def classify(x_train, y_train, x_validation, labels_validation):\n",
        "    # Instantiate network and optimizer\n",
        "    net = Discriminator()\n",
        "    opt = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "\n",
        "    # Train the classifier\n",
        "    train_classifier(opt, net, x_train, y_train)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        # Calculate predictions for all images\n",
        "        y_pred = net(x_validation)\n",
        "\n",
        "        # Initialize counters\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "        TN = 0\n",
        "        FN = 0\n",
        "        per_digit_percent = {i: 0 for i in range(10)}\n",
        "\n",
        "        # Calculate metrics for each digit\n",
        "        for digit in range(10):\n",
        "            # Select images of this digit\n",
        "            mask = labels_validation == digit\n",
        "            y_pred_digit = y_pred[mask]\n",
        "            y_true_digit = (labels_validation[mask] == digit).float().view(-1, 1)\n",
        "\n",
        "            # Predictions for this digit\n",
        "            pred_positive = (y_pred_digit > 0.5).float()\n",
        "\n",
        "            if digit == digit:  # Chosen digit\n",
        "                TP = (pred_positive == 1).sum().item()\n",
        "                FN = (pred_positive == 0).sum().item()\n",
        "                # Save misclassified images (FN)\n",
        "                fn_indices = (labels_validation == digit) & (y_pred[:, 0] <= 0.5)\n",
        "                for idx, fn_idx in enumerate(torch.where(fn_indices)[0][:5]):  # Save up to 5\n",
        "                    show_image(x_validation[fn_idx], f\"fn_digit_{digit}_{idx}.png\", scale=SCALE_01)\n",
        "            else:  # Other digits\n",
        "                FP_digit = (pred_positive == 1).sum().item()\n",
        "                TN_digit = (pred_positive == 0).sum().item()\n",
        "                FP += FP_digit\n",
        "                TN += TN_digit\n",
        "                # Save misclassified images (FP)\n",
        "                fp_indices = (labels_validation == digit) & (y_pred[:, 0] > 0.5)\n",
        "                for idx, fp_idx in enumerate(torch.where(fp_indices)[0][:5]):  # Save up to 5\n",
        "                    show_image(x_validation[fp_idx], f\"fp_digit_{digit}_{idx}.png\", scale=SCALE_01)\n",
        "\n",
        "                # Calculate percentage classified as chosen digit\n",
        "                total = mask.sum().item()\n",
        "                if total > 0:\n",
        "                    per_digit_percent[digit] = (FP_digit / total) * 100\n",
        "\n",
        "        # Calculate metrics\n",
        "        total = TP + TN + FP + FN\n",
        "        accuracy = (TP + TN) / total * 100 if total > 0 else 0\n",
        "        precision = TP / (TP + FP) * 100 if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) * 100 if (TP + FN) > 0 else 0\n",
        "\n",
        "        # Print results\n",
        "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "        print(f\"Precision: {precision:.2f}%\")\n",
        "        print(f\"Recall: {recall:.2f}%\")\n",
        "        print(\"Percentage classified as chosen digit ({}):\".format(digit))\n",
        "        for d, percent in per_digit_percent.items():\n",
        "            print(f\"Digit {d}: {percent:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt4nh87Z4pQM"
      },
      "source": [
        "# GAN (5 TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpzYjdRH7J8u"
      },
      "source": [
        "# TODO 6: Change number of total training iterations for GAN, for the discriminator and for the generator\n",
        "n = 10    # Total GAN iterations\n",
        "n1 = 50   # Discriminator iterations per GAN iteration\n",
        "n2 = 50   # Generator iterations per GAN iteration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZsKuRXK4uS2"
      },
      "source": [
        "# TODO 7\n",
        "# Change Network architecture of the generator network. It should have 100 inputs (will be random numbers) and 784 outputs (one for each pixel, each between 0 and 1)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(100, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r28Lozz45AoO"
      },
      "source": [
        "# TODO 8\n",
        "# Implement training loop for the discriminator, given real and fake data:\n",
        "# for i in range(n1):\n",
        "#     zero gradients\n",
        "#     calculate predictions for the x known as real\n",
        "#     calculate loss, comparing the predictions with a tensor consisting of 1s (we want all of these samples to be classified as real)\n",
        "#     calculate the gradient (loss_true.backward())\n",
        "#     calculate predictions for the x known as fake\n",
        "#     calculate loss, comparing the predictions with a tensor consisting of 0s (we want all of these samples to be classified as fake)\n",
        "#     calculate the gradient (loss_false.backward())\n",
        "#     print i and both of the loss values\n",
        "#     perform an optimizer step\n",
        "def train_discriminator(opt, discriminator, x_true, x_false):\n",
        "    print(\"Training discriminator\")\n",
        "    discriminator.train()\n",
        "    for i in range(n1):\n",
        "        opt.zero_grad()  # Zero gradients\n",
        "\n",
        "        # Real images\n",
        "        pred_true = discriminator(x_true)\n",
        "        loss_true = loss_fn(pred_true, torch.ones_like(pred_true))\n",
        "        loss_true.backward()\n",
        "\n",
        "        # Fake images\n",
        "        pred_false = discriminator(x_false)\n",
        "        loss_false = loss_fn(pred_false, torch.zeros_like(pred_false))\n",
        "        loss_false.backward()\n",
        "\n",
        "        print(f\"Iteration {i}, Real Loss: {loss_true.item():.4f}, Fake Loss: {loss_false.item():.4f}\")\n",
        "        opt.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeN1dXqe5Ct4"
      },
      "source": [
        "# TODO 9\n",
        "# Implement training loop for the generator:\n",
        "# for i in range(n2):\n",
        "#     zero gradients\n",
        "#     generate some random inputs\n",
        "#     calculate generated images by passing these inputs to the generator\n",
        "#     pass the generated images to the discriminator to predict if they are true or fake\n",
        "#     calculate the loss, comparing the predictions with a tensor of 1s (the *generator* wants the discriminator to classify its images as real)\n",
        "#     calculate the gradient (loss.backward())\n",
        "#     print i and the loss\n",
        "#     perform an optimization step\n",
        "def train_generator(opt, generator, discriminator):\n",
        "    print(\"Training generator\")\n",
        "    generator.train()\n",
        "    for i in range(n2):\n",
        "        opt.zero_grad()  # Zero gradients\n",
        "\n",
        "        # Generate random noise\n",
        "        noise = torch.randn(100, 100)\n",
        "        fake_images = generator(noise)\n",
        "\n",
        "        # Pass fake images through discriminator\n",
        "        pred = discriminator(fake_images)\n",
        "        loss = loss_fn(pred, torch.ones_like(pred))  # Generator wants fake images to be classified as real\n",
        "\n",
        "        loss.backward()\n",
        "        print(f\"Iteration {i}, Loss: {loss.item():.4f}\")\n",
        "        opt.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BthTT_985tYS"
      },
      "source": [
        "# TODO 10\n",
        "# Implement GAN training loop:\n",
        "# Generate some random images (with torch.rand) as an initial collection of fakes\n",
        "# Instantiate the two networks and two optimizers (one for each network!)\n",
        "# for i in range(n):\n",
        "#    call train_discriminator with the given real images and the collection of fake images\n",
        "#    call train_generator\n",
        "#    generate some images with the current generator, and add a random selection of old fake images (e.g. 100 random old ones, and 100new ones = 200 in total)\n",
        "#    this will be your new collection of fake images\n",
        "#    save some of the current fake images to a file (use a filename like \"sample_%d_%d.png\"%(i,j) so you have some samples from each iteration so you can see if the network improves)\n",
        "# If you read the todos above, your training code will print the loss in each iteration. The loss for the discriminator and the generator should decrease each time their respective training functions are called\n",
        "# The images should start to look like numbers after just a few (could be after 1 or 2 already, or 3-10) iterations of *this* loop\n",
        "def gan(x_real):\n",
        "    # Initialize fake image repository\n",
        "    x_false = torch.rand((100, 784))\n",
        "\n",
        "    # Instantiate networks and optimizers\n",
        "    generator = Generator()\n",
        "    discriminator = Discriminator()\n",
        "    opt_g = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
        "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    for i in range(n):\n",
        "        # Train discriminator\n",
        "        train_discriminator(opt_d, discriminator, x_real, x_false.detach())\n",
        "\n",
        "        # Train generator\n",
        "        train_generator(opt_g, generator, discriminator)\n",
        "\n",
        "        # Generate new fake images\n",
        "        with torch.no_grad():\n",
        "            noise = torch.randn(100, 100)\n",
        "            new_fakes = generator(noise)\n",
        "\n",
        "        # Update fake image repository (50 old + 50 new)\n",
        "        indices = torch.randperm(x_false.size(0))[:50]\n",
        "        x_false = torch.cat((x_false[indices], new_fakes[:50]), dim=0)\n",
        "\n",
        "        # Save sample images\n",
        "        for j in range(5):  # Save 5 samples per iteration\n",
        "            show_image(new_fakes[j], f\"sample_{i}_{j}.png\", scale=SCALE_01)\n",
        "\n",
        "    show_image(x_real[0], \"train_0.png\", scale=SCALE_01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXDLr4qX5QDV"
      },
      "source": [
        "# Main (no TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw5xvVZI2UN_"
      },
      "source": [
        "def main(rungan):\n",
        "    \"\"\"\n",
        "    You do not have to change this function!\n",
        "\n",
        "    It will:\n",
        "        automatically download the data set if it doesn't exist yet\n",
        "        make sure all tensor shapes are correct\n",
        "        normalize the images (all pixels between 0 and 1)\n",
        "        provide labels for the classification task (0 for all images that are not your digit, 1 for the ones that are)\n",
        "        extract the images of your chosen digit for the GAN\n",
        "    \"\"\"\n",
        "    train = torchvision.datasets.MNIST(\".\", download=True)\n",
        "    x_train = train.data.float().view(-1,28*28)/255.0\n",
        "    labels_train = train.targets\n",
        "    y_train = (labels_train == digit).float().view(-1,1)\n",
        "\n",
        "    validation = torchvision.datasets.MNIST(\".\", train=False)\n",
        "    x_validation = validation.data.float().view(-1,28*28)/255.0\n",
        "    labels_validation = validation.targets\n",
        "\n",
        "    if rungan:\n",
        "        gan(x_train[labels_train == digit])\n",
        "    else:\n",
        "        classify(x_train, y_train, x_validation, labels_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7yHoNrZ5Svz"
      },
      "source": [
        "# Test call (TODO: TEST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQm0AL2X2tzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a747afa9-6b0f-4697-b909-1873bf31b46a"
      },
      "source": [
        "# NOTE: This will not work until you have done TODO 1 above!\n",
        "# If you have not done TODO 1 yet, you will get: AttributeError: 'bool' object has no attribute 'float'\n",
        "GAN = False\n",
        "main(GAN)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 114836390.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 33061051.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 36478529.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4438613.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    }
  ]
}